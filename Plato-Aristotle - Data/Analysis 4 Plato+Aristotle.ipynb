{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5912bfa5-588e-45df-8c57-1eca9b7a11fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6768bf81-475c-49e1-9d01-1669510aa02c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved at: /Users/zey/Desktop/COMPUTER PROGRAMMING/newnew\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import os\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# Replace with the absolute path to your dataset\n",
    "dataset_path = r'/Users/zey/Desktop/COMPUTER PROGRAMMING/cleaned_data.csv'\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {dataset_path}\")\n",
    "cleaned_data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Step 2: Define the regression models\n",
    "\n",
    "# Model 1: Baseline model\n",
    "model_1_formula = 'SD_diff ~ Aristotle + Shock + Aristotle:Shock'\n",
    "model_1 = ols(model_1_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 2: Add V_2 and V_diff_nonabs\n",
    "model_2_formula = model_1_formula + ' + V_2 + V_diff_nonabs'\n",
    "model_2 = ols(model_2_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 3: Add SD_1\n",
    "model_3_formula = model_2_formula + ' + SD_1'\n",
    "model_3 = ols(model_3_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 4: Add GPT_Usage and Algorithmic_Liking along with SD_1\n",
    "model_4_formula = model_3_formula + ' + GPT_Usage + Algorithmic_liking'\n",
    "model_4 = ols(model_4_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 5: Add Knowledge_Depth_1 and Knowledge_Depth_2, exclude GPT_Usage and Algorithmic_Liking\n",
    "model_5_formula = model_3_formula + ' + Knowledge_Depth_1 + Knowledge_Depth_2'\n",
    "model_5 = ols(model_5_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Collect models into a list\n",
    "models = [model_1, model_2, model_3, model_4, model_5]\n",
    "model_names = ['Model 1', 'Model 2', 'Model 3', 'Model 4', 'Model 5']\n",
    "\n",
    "# Step 3: Format results for all models\n",
    "\n",
    "def format_coef_pval(coef, pval):\n",
    "    return f\"{coef:.4f}{'*' if pval < 0.1 else ''}\"  # Add asterisk for significance\n",
    "\n",
    "formatted_results = pd.DataFrame()\n",
    "for model_name, model in zip(model_names, models):\n",
    "    model_data = {\n",
    "        var: format_coef_pval(coef, model.pvalues.get(var, float('nan')))\n",
    "        for var, coef in model.params.items()\n",
    "    }\n",
    "    model_df = pd.DataFrame.from_dict(model_data, orient='index', columns=[model_name])\n",
    "    formatted_results = pd.concat([formatted_results, model_df], axis=1)\n",
    "\n",
    "# Reorder variables to match the desired order for display\n",
    "variable_order = [\n",
    "    \"Intercept\", \"Aristotle\", \"Shock\", \"Aristotle:Shock\",\n",
    "    \"V_2\", \"V_diff_nonabs\",\n",
    "    \"SD_1\", \"GPT_Usage\", \"Algorithmic_liking\",\n",
    "    \"Knowledge_Depth_1\", \"Knowledge_Depth_2\"\n",
    "]\n",
    "formatted_results = formatted_results.reindex(variable_order).reset_index()\n",
    "formatted_results.columns = ['Variable'] + model_names\n",
    "\n",
    "# Step 4: Perform Variance Inflation Factor (VIF) analysis for Model 5\n",
    "vif_data = cleaned_data[['Aristotle', 'Shock', 'V_2', 'V_diff_nonabs',\n",
    "                         'SD_1', 'Knowledge_Depth_1', 'Knowledge_Depth_2']]\n",
    "vif_values = pd.DataFrame({\n",
    "    \"Variable\": vif_data.columns,\n",
    "    \"VIF\": [variance_inflation_factor(vif_data.values, i) for i in range(vif_data.shape[1])]\n",
    "})\n",
    "\n",
    "# Step 5: Add R-squared and Adjusted R-squared values to the formatted results\n",
    "rsquared_values = [model.rsquared for model in models]\n",
    "adjusted_rsquared_values = [model.rsquared_adj for model in models]\n",
    "\n",
    "rsquared_data = pd.DataFrame({\n",
    "    \"Variable\": [\"R-squared\", \"Adjusted R-squared\"],\n",
    "    **{model_name: [f\"{rsq:.4f}\", f\"{adj_rsq:.4f}\"] for model_name, rsq, adj_rsq in zip(model_names, rsquared_values, adjusted_rsquared_values)}\n",
    "})\n",
    "\n",
    "formatted_results_with_rsquared = pd.concat([formatted_results, rsquared_data], ignore_index=True)\n",
    "\n",
    "# Step 6: Save regression results and VIF analysis to a Word document\n",
    "# Replace with the desired absolute path for saving the Word document\n",
    "word_file_path = r'/Users/zey/Desktop/COMPUTER PROGRAMMING/newnew'\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading('Regression Results and Analysis', level=1)\n",
    "\n",
    "# Add regression results table to the document\n",
    "doc.add_heading('Regression Results', level=2)\n",
    "table = doc.add_table(rows=1, cols=formatted_results_with_rsquared.shape[1])\n",
    "table.style = 'Table Grid'\n",
    "\n",
    "# Add headers\n",
    "header_cells = table.rows[0].cells\n",
    "for i, column_name in enumerate(formatted_results_with_rsquared.columns):\n",
    "    header_cells[i].text = column_name\n",
    "\n",
    "# Add rows\n",
    "for index, row in formatted_results_with_rsquared.iterrows():\n",
    "    cells = table.add_row().cells\n",
    "    for i, value in enumerate(row):\n",
    "        cells[i].text = str(value)\n",
    "\n",
    "# Add VIF analysis to the document\n",
    "doc.add_heading('VIF Analysis for Model 5', level=2)\n",
    "vif_table = doc.add_table(rows=1, cols=vif_values.shape[1])\n",
    "vif_table.style = 'Table Grid'\n",
    "\n",
    "# Add headers for VIF table\n",
    "vif_header_cells = vif_table.rows[0].cells\n",
    "for i, column_name in enumerate(vif_values.columns):\n",
    "    vif_header_cells[i].text = column_name\n",
    "\n",
    "# Add rows for VIF table\n",
    "for index, row in vif_values.iterrows():\n",
    "    vif_cells = vif_table.add_row().cells\n",
    "    for i, value in enumerate(row):\n",
    "        vif_cells[i].text = str(value)\n",
    "\n",
    "# Save the document\n",
    "doc.save(word_file_path)\n",
    "print(f\"Document saved at: {word_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fe10466-f17f-4cf9-a324-859ac66e2408",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved at: /Users/zey/Desktop/COMPUTER PROGRAMMING/newnew\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import os\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# Replace with the absolute path to your dataset\n",
    "dataset_path = r'/Users/zey/Desktop/COMPUTER PROGRAMMING/cleaned_data.csv'\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {dataset_path}\")\n",
    "cleaned_data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Step 2: Define the regression models\n",
    "\n",
    "# Model 1: Baseline model\n",
    "model_1_formula = 'SD_diff ~ Aristotle + Shock + Aristotle:Shock'\n",
    "model_1 = ols(model_1_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 2: Add V_2 and V_diff_nonabs\n",
    "model_2_formula = model_1_formula + ' + V_2 + V_diff_nonabs'\n",
    "model_2 = ols(model_2_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 3: Add SD_1\n",
    "model_3_formula = model_2_formula + ' + SD_1'\n",
    "model_3 = ols(model_3_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 4: Add GPT_Usage and Algorithmic_Liking along with SD_1\n",
    "model_4_formula = model_3_formula + ' + GPT_Usage + Algorithmic_liking'\n",
    "model_4 = ols(model_4_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 5: Add Knowledge_Depth_1 and Knowledge_Depth_2, exclude GPT_Usage and Algorithmic_Liking\n",
    "model_5_formula = model_3_formula + ' + Knowledge_Depth_1 + Knowledge_Depth_2'\n",
    "model_5 = ols(model_5_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Collect models into a list\n",
    "models = [model_1, model_2, model_3, model_4, model_5]\n",
    "model_names = ['Model 1', 'Model 2', 'Model 3', 'Model 4', 'Model 5']\n",
    "\n",
    "# Step 3: Format results for all models\n",
    "\n",
    "def format_coef_pval(coef, pval):\n",
    "    return f\"{coef:.4f}{'*' if pval < 0.1 else ''}\"  # Add asterisk for significance\n",
    "\n",
    "formatted_results = pd.DataFrame()\n",
    "for model_name, model in zip(model_names, models):\n",
    "    model_data = {\n",
    "        var: format_coef_pval(coef, model.pvalues.get(var, float('nan')))\n",
    "        for var, coef in model.params.items()\n",
    "    }\n",
    "    model_df = pd.DataFrame.from_dict(model_data, orient='index', columns=[model_name])\n",
    "    formatted_results = pd.concat([formatted_results, model_df], axis=1)\n",
    "\n",
    "# Reorder variables to match the desired order for display\n",
    "variable_order = [\n",
    "    \"Intercept\", \"Aristotle\", \"Shock\", \"Aristotle:Shock\",\n",
    "    \"V_2\", \"V_diff_nonabs\",\n",
    "    \"SD_1\", \"GPT_Usage\", \"Algorithmic_liking\",\n",
    "    \"Knowledge_Depth_1\", \"Knowledge_Depth_2\"\n",
    "]\n",
    "formatted_results = formatted_results.reindex(variable_order).reset_index()\n",
    "formatted_results.columns = ['Variable'] + model_names\n",
    "\n",
    "# Step 4: Perform Variance Inflation Factor (VIF) analysis for Model 5\n",
    "vif_data = cleaned_data[['Aristotle', 'Shock', 'V_2', 'V_diff_nonabs',\n",
    "                         'SD_1', 'Knowledge_Depth_1', 'Knowledge_Depth_2']]\n",
    "vif_values = pd.DataFrame({\n",
    "    \"Variable\": vif_data.columns,\n",
    "    \"VIF\": [variance_inflation_factor(vif_data.values, i) for i in range(vif_data.shape[1])]\n",
    "})\n",
    "\n",
    "# Step 5: Add R-squared and Adjusted R-squared values to the formatted results\n",
    "rsquared_values = [model.rsquared for model in models]\n",
    "adjusted_rsquared_values = [model.rsquared_adj for model in models]\n",
    "\n",
    "rsquared_data = pd.DataFrame({\n",
    "    \"Variable\": [\"R-squared\", \"Adjusted R-squared\"],\n",
    "    **{model_name: [f\"{rsq:.4f}\", f\"{adj_rsq:.4f}\"] for model_name, rsq, adj_rsq in zip(model_names, rsquared_values, adjusted_rsquared_values)}\n",
    "})\n",
    "\n",
    "formatted_results_with_rsquared = pd.concat([formatted_results, rsquared_data], ignore_index=True)\n",
    "\n",
    "# Step 6: Save regression results and VIF analysis to a Word document\n",
    "# Replace with the desired absolute path for saving the Word document\n",
    "word_file_path = r'/Users/zey/Desktop/COMPUTER PROGRAMMING/newnew'\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading('Regression Results and Analysis', level=1)\n",
    "\n",
    "# Add regression results table to the document\n",
    "doc.add_heading('Regression Results', level=2)\n",
    "table = doc.add_table(rows=1, cols=formatted_results_with_rsquared.shape[1])\n",
    "table.style = 'Table Grid'\n",
    "\n",
    "# Add headers\n",
    "header_cells = table.rows[0].cells\n",
    "for i, column_name in enumerate(formatted_results_with_rsquared.columns):\n",
    "    header_cells[i].text = column_name\n",
    "\n",
    "# Add rows\n",
    "for index, row in formatted_results_with_rsquared.iterrows():\n",
    "    cells = table.add_row().cells\n",
    "    for i, value in enumerate(row):\n",
    "        cells[i].text = str(value)\n",
    "\n",
    "# Add VIF analysis to the document\n",
    "doc.add_heading('VIF Analysis for Model 5', level=2)\n",
    "vif_table = doc.add_table(rows=1, cols=vif_values.shape[1])\n",
    "vif_table.style = 'Table Grid'\n",
    "\n",
    "# Add headers for VIF table\n",
    "vif_header_cells = vif_table.rows[0].cells\n",
    "for i, column_name in enumerate(vif_values.columns):\n",
    "    vif_header_cells[i].text = column_name\n",
    "\n",
    "# Add rows for VIF table\n",
    "for index, row in vif_values.iterrows():\n",
    "    vif_cells = vif_table.add_row().cells\n",
    "    for i, value in enumerate(row):\n",
    "        vif_cells[i].text = str(value)\n",
    "\n",
    "# Save the document\n",
    "doc.save(word_file_path)\n",
    "print(f\"Document saved at: {word_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0fb5b37-a599-4f77-9036-598a66a70b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Regression Results ===\n",
      "\n",
      "Model 1\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                SD_diff   R-squared:                       0.024\n",
      "Model:                            OLS   Adj. R-squared:                 -0.026\n",
      "Method:                 Least Squares   F-statistic:                    0.4748\n",
      "Date:                Thu, 28 Nov 2024   Prob (F-statistic):              0.701\n",
      "Time:                        16:02:36   Log-Likelihood:                -78.495\n",
      "No. Observations:                  63   AIC:                             165.0\n",
      "Df Residuals:                      59   BIC:                             173.6\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept           0.2667      0.224      1.188      0.240      -0.182       0.716\n",
      "Aristotle           0.2667      0.317      0.840      0.404      -0.368       0.902\n",
      "Shock              -0.0902      0.308     -0.293      0.771      -0.706       0.526\n",
      "Aristotle:Shock    -0.1306      0.439     -0.298      0.767      -1.008       0.747\n",
      "==============================================================================\n",
      "Omnibus:                        2.517   Durbin-Watson:                   1.902\n",
      "Prob(Omnibus):                  0.284   Jarque-Bera (JB):                1.686\n",
      "Skew:                           0.316   Prob(JB):                        0.430\n",
      "Kurtosis:                       3.494   Cond. No.                         6.96\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Model 2\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                SD_diff   R-squared:                       0.159\n",
      "Model:                            OLS   Adj. R-squared:                  0.086\n",
      "Method:                 Least Squares   F-statistic:                     2.161\n",
      "Date:                Thu, 28 Nov 2024   Prob (F-statistic):             0.0711\n",
      "Time:                        16:02:36   Log-Likelihood:                -73.778\n",
      "No. Observations:                  63   AIC:                             159.6\n",
      "Df Residuals:                      57   BIC:                             172.4\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept          -0.0116      0.446     -0.026      0.979      -0.904       0.881\n",
      "Aristotle           0.1015      0.306      0.332      0.741      -0.511       0.714\n",
      "Shock              -0.0413      0.295     -0.140      0.889      -0.632       0.550\n",
      "Aristotle:Shock     0.2240      0.446      0.503      0.617      -0.669       1.117\n",
      "V_2                 0.0005      0.006      0.083      0.934      -0.012       0.013\n",
      "V_diff_nonabs       0.0367      0.013      2.898      0.005       0.011       0.062\n",
      "==============================================================================\n",
      "Omnibus:                        5.012   Durbin-Watson:                   2.054\n",
      "Prob(Omnibus):                  0.082   Jarque-Bera (JB):                4.665\n",
      "Skew:                           0.382   Prob(JB):                       0.0970\n",
      "Kurtosis:                       4.092   Cond. No.                         381.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Model 3\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                SD_diff   R-squared:                       0.377\n",
      "Model:                            OLS   Adj. R-squared:                  0.310\n",
      "Method:                 Least Squares   F-statistic:                     5.643\n",
      "Date:                Thu, 28 Nov 2024   Prob (F-statistic):           0.000123\n",
      "Time:                        16:02:36   Log-Likelihood:                -64.350\n",
      "No. Observations:                  63   AIC:                             142.7\n",
      "Df Residuals:                      56   BIC:                             157.7\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept           1.0381      0.454      2.286      0.026       0.128       1.948\n",
      "Aristotle          -0.2703      0.279     -0.970      0.336      -0.828       0.288\n",
      "Shock              -0.2012      0.259     -0.777      0.441      -0.720       0.318\n",
      "Aristotle:Shock     0.5780      0.395      1.462      0.149      -0.214       1.370\n",
      "V_2                 0.0139      0.006      2.287      0.026       0.002       0.026\n",
      "V_diff_nonabs       0.0267      0.011      2.380      0.021       0.004       0.049\n",
      "SD_1               -0.3664      0.083     -4.420      0.000      -0.532      -0.200\n",
      "==============================================================================\n",
      "Omnibus:                        3.104   Durbin-Watson:                   1.840\n",
      "Prob(Omnibus):                  0.212   Jarque-Bera (JB):                2.535\n",
      "Skew:                           0.204   Prob(JB):                        0.282\n",
      "Kurtosis:                       3.894   Cond. No.                         414.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Model 4\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                SD_diff   R-squared:                       0.383\n",
      "Model:                            OLS   Adj. R-squared:                  0.292\n",
      "Method:                 Least Squares   F-statistic:                     4.191\n",
      "Date:                Thu, 28 Nov 2024   Prob (F-statistic):           0.000591\n",
      "Time:                        16:02:36   Log-Likelihood:                -64.033\n",
      "No. Observations:                  63   AIC:                             146.1\n",
      "Df Residuals:                      54   BIC:                             165.4\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept              1.0322      0.699      1.477      0.145      -0.369       2.433\n",
      "Aristotle             -0.2787      0.284     -0.982      0.331      -0.848       0.290\n",
      "Shock                 -0.1730      0.269     -0.643      0.523      -0.713       0.367\n",
      "Aristotle:Shock        0.5520      0.402      1.372      0.176      -0.255       1.358\n",
      "V_2                    0.0143      0.006      2.314      0.024       0.002       0.027\n",
      "V_diff_nonabs          0.0269      0.012      2.337      0.023       0.004       0.050\n",
      "SD_1                  -0.3793      0.087     -4.375      0.000      -0.553      -0.206\n",
      "GPT_Usage             -0.0237      0.096     -0.247      0.806      -0.216       0.169\n",
      "Algorithmic_liking     0.0517      0.075      0.693      0.491      -0.098       0.201\n",
      "==============================================================================\n",
      "Omnibus:                        3.097   Durbin-Watson:                   1.858\n",
      "Prob(Omnibus):                  0.213   Jarque-Bera (JB):                2.416\n",
      "Skew:                           0.245   Prob(JB):                        0.299\n",
      "Kurtosis:                       3.824   Cond. No.                         554.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Model 5\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                SD_diff   R-squared:                       0.436\n",
      "Model:                            OLS   Adj. R-squared:                  0.352\n",
      "Method:                 Least Squares   F-statistic:                     5.212\n",
      "Date:                Thu, 28 Nov 2024   Prob (F-statistic):           7.55e-05\n",
      "Time:                        16:02:36   Log-Likelihood:                -61.222\n",
      "No. Observations:                  63   AIC:                             140.4\n",
      "Df Residuals:                      54   BIC:                             159.7\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept            -0.0030      0.711     -0.004      0.997      -1.429       1.423\n",
      "Aristotle            -0.3436      0.272     -1.263      0.212      -0.889       0.202\n",
      "Shock                -0.2023      0.252     -0.802      0.426      -0.708       0.304\n",
      "Aristotle:Shock       0.6334      0.384      1.648      0.105      -0.137       1.404\n",
      "V_2                   0.0132      0.006      2.212      0.031       0.001       0.025\n",
      "V_diff_nonabs         0.0272      0.011      2.468      0.017       0.005       0.049\n",
      "SD_1                 -0.3804      0.081     -4.713      0.000      -0.542      -0.219\n",
      "Knowledge_Depth_1    -0.0962      0.091     -1.059      0.294      -0.278       0.086\n",
      "Knowledge_Depth_2     0.2874      0.121      2.374      0.021       0.045       0.530\n",
      "==============================================================================\n",
      "Omnibus:                        8.180   Durbin-Watson:                   1.587\n",
      "Prob(Omnibus):                  0.017   Jarque-Bera (JB):                9.068\n",
      "Skew:                           0.561   Prob(JB):                       0.0107\n",
      "Kurtosis:                       4.482   Cond. No.                         591.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "=== Variance Inflation Factor (VIF) ===\n",
      "            Variable        VIF\n",
      "0          Aristotle   2.065296\n",
      "1              Shock   2.398477\n",
      "2                V_2  20.735523\n",
      "3      V_diff_nonabs   1.877937\n",
      "4               SD_1  17.784441\n",
      "5  Knowledge_Depth_1  31.278277\n",
      "6  Knowledge_Depth_2  42.625023\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# Replace with the absolute path to your dataset\n",
    "dataset_path = r'/Users/zey/Desktop/COMPUTER PROGRAMMING/cleaned_data.csv'\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {dataset_path}\")\n",
    "cleaned_data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Step 2: Define the regression models\n",
    "\n",
    "# Model 1: Baseline model\n",
    "model_1_formula = 'SD_diff ~ Aristotle + Shock + Aristotle:Shock'\n",
    "model_1 = ols(model_1_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 2: Add V_2 and V_diff_nonabs\n",
    "model_2_formula = model_1_formula + ' + V_2 + V_diff_nonabs'\n",
    "model_2 = ols(model_2_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 3: Add SD_1\n",
    "model_3_formula = model_2_formula + ' + SD_1'\n",
    "model_3 = ols(model_3_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 4: Add GPT_Usage and Algorithmic_Liking along with SD_1\n",
    "model_4_formula = model_3_formula + ' + GPT_Usage + Algorithmic_liking'\n",
    "model_4 = ols(model_4_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 5: Add Knowledge_Depth_1 and Knowledge_Depth_2, exclude GPT_Usage and Algorithmic_Liking\n",
    "model_5_formula = model_3_formula + ' + Knowledge_Depth_1 + Knowledge_Depth_2'\n",
    "model_5 = ols(model_5_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Collect models into a list\n",
    "models = [model_1, model_2, model_3, model_4, model_5]\n",
    "model_names = ['Model 1', 'Model 2', 'Model 3', 'Model 4', 'Model 5']\n",
    "\n",
    "# Step 3: Print regression results\n",
    "print(\"\\n=== Regression Results ===\")\n",
    "for name, model in zip(model_names, models):\n",
    "    print(f\"\\n{name}\")\n",
    "    print(model.summary())\n",
    "\n",
    "# Step 4: Perform Variance Inflation Factor (VIF) analysis for Model 5\n",
    "vif_data = cleaned_data[['Aristotle', 'Shock', 'V_2', 'V_diff_nonabs',\n",
    "                         'SD_1', 'Knowledge_Depth_1', 'Knowledge_Depth_2']]\n",
    "vif_values = pd.DataFrame({\n",
    "    \"Variable\": vif_data.columns,\n",
    "    \"VIF\": [variance_inflation_factor(vif_data.values, i) for i in range(vif_data.shape[1])]\n",
    "})\n",
    "\n",
    "# Step 5: Print VIF values\n",
    "print(\"\\n=== Variance Inflation Factor (VIF) ===\")\n",
    "print(vif_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ad92bd3-5187-4ee5-8d65-a6d20a674c45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Variable        VIF\n",
      "0          Aristotle   1.093869\n",
      "1              Shock   1.158148\n",
      "2                V_2   1.550890\n",
      "3      V_diff_nonabs   1.364199\n",
      "4               SD_1   1.396106\n",
      "5  Knowledge_Depth_1   1.407039\n",
      "6  Knowledge_Depth_2   1.338436\n",
      "7          Intercept  66.818094\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example: Assuming `data` is your DataFrame with independent variables\n",
    "def calculate_vif_with_constant(data):\n",
    "    \"\"\"Calculate VIF, including a constant (intercept).\"\"\"\n",
    "    # Add a constant column\n",
    "    data_with_constant = data.copy()\n",
    "    data_with_constant['Intercept'] = 1\n",
    "\n",
    "    # Calculate VIF for all variables including the constant\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = data_with_constant.columns\n",
    "    vif_data[\"VIF\"] = [\n",
    "        variance_inflation_factor(data_with_constant.values, i)\n",
    "        for i in range(data_with_constant.shape[1])\n",
    "    ]\n",
    "    return vif_data\n",
    "\n",
    "# Example Usage\n",
    "# Assuming `cleaned_data` contains the independent variables for the regression\n",
    "independent_vars = cleaned_data[['Aristotle', 'Shock', 'V_2', 'V_diff_nonabs', \n",
    "                                  'SD_1', 'Knowledge_Depth_1', 'Knowledge_Depth_2']]\n",
    "vif_results_with_constant = calculate_vif_with_constant(independent_vars)\n",
    "\n",
    "# Print the VIF results\n",
    "print(vif_results_with_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fd2da5e-85f2-415a-984b-12a8eceab447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformula\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ols\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutliers_influence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variance_inflation_factor\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Function to calculate VIF\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_vif\u001b[39m(X):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/api.py:125\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenmod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m genmod\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    116\u001b[0m     GEE,\n\u001b[1;32m    117\u001b[0m     GLM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m     families,\n\u001b[1;32m    124\u001b[0m )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m graphics\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgofplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProbPlot, qqline, qqplot, qqplot_2samples\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbayes_mi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MI, BayesGaussMI\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/graphics/api.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgofplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m qqplot\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplottools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rainbow\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregressionplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     abline_plot,\n\u001b[1;32m     11\u001b[0m     influence_plot,\n\u001b[1;32m     12\u001b[0m     plot_ccpr,\n\u001b[1;32m     13\u001b[0m     plot_ccpr_grid,\n\u001b[1;32m     14\u001b[0m     plot_fit,\n\u001b[1;32m     15\u001b[0m     plot_leverage_resid2,\n\u001b[1;32m     16\u001b[0m     plot_partregress,\n\u001b[1;32m     17\u001b[0m     plot_partregress_grid,\n\u001b[1;32m     18\u001b[0m     plot_regress_exog,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabline_plot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeanplot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviolinplot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/graphics/regressionplots.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneralized_linear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GLM\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnonparametric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msmoothers_lowess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lowess\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GLS, OLS, WLS\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msandbox\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredstd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wls_prediction_std\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/nonparametric/smoothers_lowess.py:11\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"Lowess - wrapper for cythonized extension\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mAuthor : Chris Jordan-Squire\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smoothers_lowess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lowess \u001b[38;5;28;01mas\u001b[39;00m _lowess\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlowess\u001b[39m(endog, exog, frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3.0\u001b[39m, it\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, xvals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, is_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m            missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m'\u001b[39m, return_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''LOWESS (Locally Weighted Scatterplot Smoothing)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    A lowess function that outs smoothed estimates of endog\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n",
      "File \u001b[0;32mstatsmodels/nonparametric/_smoothers_lowess.pyx:1\u001b[0m, in \u001b[0;36minit statsmodels.nonparametric._smoothers_lowess\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Function to calculate VIF\n",
    "def calculate_vif(X):\n",
    "    \"\"\"\n",
    "    Calculate Variance Inflation Factor (VIF) for a DataFrame of predictors, including the constant.\n",
    "    \"\"\"\n",
    "    X = sm.add_constant(X)  # Add intercept (constant) for VIF calculation\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "dataset_path = r'/Users/zey/Desktop/COMPUTER PROGRAMMING/cleaned_data.csv'\n",
    "cleaned_data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Step 2: Define the regression models\n",
    "\n",
    "# Model 1: Baseline model\n",
    "model_1_formula = 'SD_diff ~ Aristotle + Shock + Aristotle:Shock'\n",
    "model_1 = ols(model_1_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 2: Add V_2 and V_diff_nonabs\n",
    "model_2_formula = model_1_formula + ' + V_2 + V_diff_nonabs'\n",
    "model_2 = ols(model_2_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 3: Add SD_1\n",
    "model_3_formula = model_2_formula + ' + SD_1'\n",
    "model_3 = ols(model_3_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 4: Add GPT_Usage and Algorithmic_Liking along with SD_1\n",
    "model_4_formula = model_3_formula + ' + GPT_Usage + Algorithmic_liking'\n",
    "model_4 = ols(model_4_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Model 5: Add Knowledge_Depth_1 and Knowledge_Depth_2, exclude GPT_Usage and Algorithmic_Liking\n",
    "model_5_formula = model_3_formula + ' + Knowledge_Depth_1 + Knowledge_Depth_2'\n",
    "model_5 = ols(model_5_formula, data=cleaned_data).fit()\n",
    "\n",
    "# Collect models into a list\n",
    "models = [model_1, model_2, model_3, model_4, model_5]\n",
    "model_names = ['Model 1', 'Model 2', 'Model 3', 'Model 4', 'Model 5']\n",
    "\n",
    "# Step 3: Format results for all models\n",
    "print(\"\\n=== Regression Results ===\")\n",
    "for name, model in zip(model_names, models):\n",
    "    print(f\"\\n{name}\")\n",
    "    print(model.summary())\n",
    "\n",
    "# Step 4: Perform Variance Inflation Factor (VIF) analysis for Model 5\n",
    "independent_vars = cleaned_data[['Aristotle', 'Shock', 'V_2', 'V_diff_nonabs',\n",
    "                                  'SD_1', 'Knowledge_Depth_1', 'Knowledge_Depth_2']]\n",
    "vif_results = calculate_vif(independent_vars)\n",
    "\n",
    "# Print the VIF results\n",
    "print(\"\\n=== Variance Inflation Factor (VIF) with Intercept ===\")\n",
    "print(vif_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e31936-748b-4c96-bb91-7bc4d2c21b65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
